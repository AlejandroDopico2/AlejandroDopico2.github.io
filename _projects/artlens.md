---
layout: page
title: ArtLens
description: HackUDC 2025 Edition
img: assets/img/projects/artlens/icon.jpeg
importance: 1
category: hackathons
related_publications: true
---

Have you ever visited a museum and, without a guide, felt a little lost‚Äîstanding in front of incredible works of art, but not really knowing what you're looking at?

That was the motivation behind **ArtLens**, a mobile app we built during **[HackUDC 2025](https://hackudc.gpul.org/)** to bring context, story, and voice to any museum visit. With just your phone, ArtLens can recognize a painting (or sculpture), describe it in detail, adapt it to your profile, and even read it aloud.

<div class="row justify-content-sm-center">
  <div class="col-sm-8 mt-3 mt-md-0">
    {% include figure.liquid path="assets/img/projects/artlens/team.jpg" title="ArtLens team" class="img-fluid rounded z-depth-1" %}
  </div>
</div>
<div class="caption">
ArtLens was developed in 36 hours and won the "Best Mobile App" prize sponsored by NomaSystems.
</div>

---

### üß† Motivation

Museums are full of stories‚Äîbut if you‚Äôre not an art historian or don‚Äôt have a guided tour, those stories often stay hidden. We wanted to change that, using AI to create a more **inclusive and personalized museum experience**.

ArtLens tries to answer the questions many of us have when visiting a museum:

> **What am I looking at?**  
> **Why is this artwork important?**  
> **What‚Äôs the story behind it?**

---

### üì± How it works

The app has three simple screens that guide the whole experience:

<div class="row">
  <div class="col-sm mt-3 mt-md-0">
    {% include figure.liquid path="assets/img/projects/artlens/home.jpeg" title="1. Choose your profile" class="img-fluid rounded z-depth-1" %}
  </div>
  <div class="col-sm mt-3 mt-md-0">
    {% include figure.liquid path="assets/img/projects/artlens/scan.jpeg" title="2. Take a photo of the artwork" class="img-fluid rounded z-depth-1" %}
  </div>
  <div class="col-sm mt-3 mt-md-0">
    {% include figure.liquid path="assets/img/projects/artlens/result.jpeg" title="3. Get your audio description" class="img-fluid rounded z-depth-1" %}
  </div>
</div>
<div class="caption">
<strong>The app flow:</strong><br>
‚ë† <em>Home</em> ‚Äì Choose your visitor profile (e.g., child, tourist, art student...)<br>
‚ë° <em>Scan</em> ‚Äì Take a photo of an artwork directly in the museum<br>
‚ë¢ <em>Result</em> ‚Äì Get a personalized description, read out loud, with a link to explore more
</div>

---

### üõ†Ô∏è Under the hood

I worked on the **backend and the AI system**, and this project was full of firsts for me:

- ‚úÖ First time using **CLIP** (by OpenAI) for visual understanding
- ‚úÖ First time working with **Milvus**, an embedding database for fast similarity search
- ‚úÖ First time building **real-time text-to-speech**, using the super simple `gTTS` library

To ensure privacy and keep things lightweight, we also ran a **local LLM** (LLaMA 3.2 via **Ollama**) on-device. That way, the entire process could run offline‚Äîan important feature in a place like a museum.

---

### üîÑ Full pipeline

Here‚Äôs how the system worked end-to-end:

1. The visitor selects a profile (e.g., child, tourist‚Ä¶)
2. Takes a photo of the artwork
3. We extract image **embeddings** using **CLIP**
4. We search those embeddings in a **Milvus** database of artworks (focused on Museo del Prado)
5. Once we identify the artwork, we generate a **prompt** for the local **LLM**, tailored to the visitor's profile
6. The LLM creates a natural, friendly explanation of the piece
7. We convert that text into **speech** using `gTTS`, providing an instant, personalized audio guide

---

### üñºÔ∏è Custom dataset from Museo del Prado

One big challenge was the lack of existing datasets for the **Museo del Prado**‚Äîespecially in Spanish. So we built our own:  
scraping, curating, and annotating a **small dataset of iconic artworks**. It was a great exercise in data wrangling and making AI more culturally grounded.

<div class="row justify-content-sm-center">
  <div class="col-sm-8 mt-3 mt-md-0">
    {% include figure.liquid path="assets/img/projects/artlens/garden.jpg" title="The Garden of Earthly Delights" class="img-fluid rounded z-depth-1" %}
  </div>
  <div class="col-sm-4 mt-3 mt-md-0">
    {% include figure.liquid path="assets/img/projects/artlens/meninas.jpg" title="Las Meninas" class="img-fluid rounded z-depth-1" %}
  </div>
</div>
<div class="caption">
We focused on the Prado Museum in Madrid, but the same system could be adapted to any collection.
</div>

---

### üéâ Final thoughts

We built ArtLens in just 36 hours during the **HackUDC 2025** hackathon.  
We didn‚Äôt sleep much, but we learned a lot‚Äîand somehow, it all worked.

Winning the **Best Mobile App** award (thanks to **NomaSystems**) was the cherry on top.  
But more than that, we were proud to create something that used AI not for automation or speed, but for **curiosity** and **cultural connection**.

Because sometimes, all you need is one simple question to unlock a masterpiece:

> **‚ÄúTell me what I‚Äôm looking at.‚Äù**
